version: '3.9'

services:

  ofelia:
    image: mcuadros/ofelia:latest
    container_name: ofelia_scheduler
    depends_on:
      - backend
    command: daemon --docker
    environment:
      - TZ=Asia/Dhaka  # Sets the timezone variable
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro # Allows Ofelia to talk to Docker
      - /etc/localtime:/etc/localtime:ro
    networks:
      - app-network



  backend:
    build: 
      context: ./backend
    container_name: django_backend

    labels:
      ofelia.enabled: "true"
      # Schedule: 0 seconds, 30 minutes, 9 hours (9:30 AM) every day
      ofelia.job-exec.agreement-update.schedule: "0 30 9 * * *"
      # The command to run inside this container
      ofelia.job-exec.agreement-update.command: "python manage.py update_agreements"

    volumes:
      - ./backend:/backend
      - static_volume:/backend/static
      - media_volume:/backend/media
    depends_on:
      - db
    environment:
      - DB_HOST=db
      - DB_NAME=atm
      - DB_USER=root
      - DB_PASSWORD=root
      - DJANGO_SUPERUSER_EMAIL=admin@sonali.com
      - DJANGO_SUPERUSER_PASSWORD=admin12345@
    ports:
      - "8003:8003"

  frontend:
    build: ./frontend
    container_name: react_frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    volumes:
      - static_volume:/static
      - media_volume:/media
      - ./frontend/nginx.conf:/etc/nginx/conf.d/default.conf:ro

  db:
    image: mysql:8.0
    container_name: mysql_db
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: atm
    volumes:
      - db_data:/var/lib/mysql
    expose:
      - "3306"


  llm_service:
    build:
      context: ./backend/LLM-fastapi # You'll need to create this directory
      dockerfile: Dockerfile.llm
    container_name: fastapi_llm_service
    volumes:
      - ./backend/LLM-fastapi:/app
      - ollama_models:/root/.ollama  # Persist Ollama models
    ports:
      - "8008:8008"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=1h
      - PYTHONUNBUFFERED=1
    working_dir: /app
    networks:
      - app-network
    command: >
      sh -c "
        ollama serve &
        sleep 5 &&
        ollama pull qwen3:0.6b &&
        uvicorn main:app --host 0.0.0.0 --port 8008 --reload
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8008/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  
volumes: 
  db_data:
  static_volume:
  media_volume:
  ollama_models:

networks:
  app-network:
    driver: bridge


